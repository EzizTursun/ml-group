{
 "metadata": {
  "name": "",
  "signature": "sha256:141aa893ff5a18eb515e79653b4175a3c43410351f5071e94cd8c4cef2774612"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Representing the Logistic Regression Hypothesis\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, we want $ 0 \\leq h_\\theta(x) \\leq 1 $\n",
      "            \n",
      "Remember this representation:           \n",
      "$ h_\\theta = g(\\theta^Tx) $      \n",
      "          \n",
      "where:      \n",
      "$ g(z) = \\frac{1}{1 + e^{-z}} $       \n",
      "       \n",
      "So our final representation is:    \n",
      "$ g(z) = \\frac{1}{1 + e^{-\\theta^Tx}} $\n",
      "\n",
      "__this is the *sigmoid* or *logistic* function__"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define the logistic function\n",
      "\n",
      "import numpy as np\n",
      "def sigmoid(x, theta=np.array(1.0)):\n",
      "    x = np.array(x)\n",
      "    theta = np.array(theta)\n",
      "    return(1 / (1 + np.exp(-x.dot(theta.T))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cool, let's visualize it (x is 'z', y is 'g(z)')\n",
      "import matplotlib.pyplot as plt\n",
      "from pylab import *\n",
      "\n",
      "# notebook magic\n",
      "%matplotlib inline\n",
      "\n",
      "# map the sigmoid function over a vector of numbers\n",
      "x = np.arange(-6, 6, .01)\n",
      "y = [ sigmoid(n) for n in x ]\n",
      "\n",
      "# add a vertical line at 0\n",
      "plt.axvline(x=0, ymin=0, ymax=1, ls='--')\n",
      "\n",
      "plt.plot(x, y, color='red', lw=2)\n",
      "plt.xlabel('z')\n",
      "plt.ylabel('g(z)')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEPCAYAAACk43iMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x41a9f50>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Implementing Logistic Regression\n",
      "__our goal is to fit the parameters $ \\theta $ to our data__\n",
      "\n",
      "\n",
      "### Interpreting the hypothesis\n",
      "__The key idea is to interpret $ h_\\theta(x) $ as the probability that y = 1 for input x__     \n",
      "In other words, if x >= 0.5 we classify it as 1, if it's < 0.5, we classify it as 0      \n",
      "\n",
      "formally:     \n",
      "$ h_\\theta(x) = p(y=1 | x;\\theta) $\n",
      ">__\"the probability that y=1, given x, parameterized by $ \\theta $\"__ - Andrew Ng        \n",
      "      \n",
      "Note the following as well:     \n",
      "$ p(y=0| x;\\theta) + p(y=1| x;\\theta) = 1 $           \n",
      "$ p(y=0| x;\\theta) = 1 - p(y=1| x;\\theta) $    \n",
      "        \n",
      "Question: what values of z cause g(z) to be > 0.5 ?\n",
      "\n",
      "Note:     \n",
      "$ h_\\theta(x) = g(\\theta^Tx) \\geq 0.5 $ whenever $ \\theta^Tx \\geq 0 $       \n",
      "and conversely:      \n",
      "$ h_\\theta(x) = g(\\theta^Tx) \\lt 0.5 $ whenever $ \\theta^Tx \\lt 0 $"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### understanding and visualizing the decision boundary\n",
      "Remember that: $ h_\\theta(x) = g(\\theta_0 + \\theta_1x_1 + \\theta_2x_2) $      \n",
      "\n",
      "__possible exercise__:\n",
      "visualize the classes of points for a random array of sample data, and a sample parameter vector     \n",
      "if params are $ \\theta = [ -3,1,1 ] $, then the line for the decision boundary is $ -x + 3 $     "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# notebook magic\n",
      "%matplotlib inline\n",
      "from numpy.random import random, randint\n",
      "\n",
      "def boundary(x):\n",
      "    x = np.float(x)\n",
      "    return (-x + 3)\n",
      "\n",
      "def random_point():\n",
      "    return (1, random()*randint(0,6), random()*randint(0,6))\n",
      "\n",
      "def decide(value):\n",
      "    if value >= 0.5:\n",
      "        return 1\n",
      "    return 0\n",
      "\n",
      "\n",
      "# an example vector of theta values\n",
      "example_theta = np.array([-3,1,1])\n",
      "\n",
      "plt.clf()\n",
      "markers = ['o', '+']\n",
      "colors = ['red', 'blue']\n",
      "points_x = [ random_point() for x in range(100) ]\n",
      "classes = [ decide(sigmoid(p, example_theta)) for p in points_x ]\n",
      "x_1 = [x[1] for x in points_x]\n",
      "x_2 = [x[2] for x in points_x]\n",
      "for i,p in enumerate(points_x):\n",
      "    x_1 = p[1]\n",
      "    x_2 = p[2]\n",
      "    c=classes[i]\n",
      "    plt.scatter(x_1, x_2, s=30.0, c=c, marker=markers[c], color=colors[c])\n",
      "    \n",
      "\n",
      "# map the sigmoid function over a vector of numbers\n",
      "x = np.arange(0, 3, .01)\n",
      "y = [ boundary(n) for n in x ]\n",
      "\n",
      "# add a vertical line at 0\n",
      "#plt.axvline(x=0, ymin=0, ymax=1, ls='--')\n",
      "\n",
      "plt.plot(x, y, color='red', lw=1, ls='--')\n",
      "plt.xlabel('x_1')\n",
      "plt.ylabel('x_2')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEQCAYAAAC5oaP8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x41a9b10>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Non-Linear decision boundaries\n",
      "__in logistic regression, to capture a non-linear boundary, we need to add polynomial features__     \n",
      "i.e.    \n",
      "$ h_\\theta(x) = g(\\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\theta_3x^2_1 + \\theta_4x^2_2) $       \n",
      "       \n",
      "Question: what happens if the $ \\theta $ values for the features above are [-1,0,0,1,1]?      \n",
      "Answer: predict y=1 when $ -1 + x^2_1 + x^2_2 \\geq 0 $       \n",
      "So the decision boundary is: $ x^2_1 + x^2_2 = 1 $ (a circle)               \n",
      "__Remember that the decision boundary is defined by $ \\theta $, not by the dataset__           \n",
      "--> higher-order polynomial features can make arbitrarily complex decision boundaries"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cost Function -- aka Optimization Objective        \n",
      "We have a training set: $ \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), ...,(x^{(m)}, y^{(m)}) \\} $          \n",
      "__each $x$ is a vector: $ [x_0, x_1, x_2, ..., x_n] $__         \n",
      "* note that $X_0 = 1$ ($\\theta_0$ is the 'bias' term)        \n",
      "since this is a classification problem, $ y \\in \\{0,1\\} $          \n",
      "       \n",
      "and remember:       \n",
      "$ g(z) = \\frac{1}{1 + e^{-\\theta^Tx}} $          \n",
      "        \n",
      "__So how do we find the right $\\theta$s?__     \n",
      "          \n",
      "For linear regression, the cost function was:         \n",
      "$J(\\theta) = \\frac{1}{m}\\sum\\limits_{i=1}^m\\frac{1}{2}(h_\\theta(x^{(i)}) - y^{(i)})^2 $\n",
      "       \n",
      "Let's represent the part after the sum as:     \n",
      "$ cost(h_\\theta(x^{(i)}, y^{(i)}) $           \n",
      "       \n",
      "So, for linear regression:     \n",
      "$ cost(h_\\theta(x^{(i)}, y^{(i)}) = \\frac{1}{2}(h_\\theta(x^{(i)}) - y^{(i)})^2 $          \n",
      "if we just define $h_\\theta(x)$ as the logistic (sigmoid) function, it's not convex    \n",
      "      \n",
      "So, redefine the cost function as:       \n",
      "          \n",
      "$ cost(h_\\theta(x), y) = \n",
      "\\begin{cases}\n",
      "-log(h_\\theta(x))~~if~~y = 1 \\\\\n",
      "-log(1 - h_\\theta(x))~~if~~y = 0\n",
      "\\end{cases} $                 \n",
      "           \n",
      "      \n",
      "### Get ready, something cool is coming....     \n",
      "because $ y = \\{0, 1\\} $      \n",
      "you can write the cost function succinctly as:      \n",
      "       \n",
      "$ cost(h_\\theta(x^{(i)}, y^{(i)}) = -y~log(h_\\theta(x)) - (1-y)log(1 - h_\\theta(x)) $    \n",
      "      \n",
      "__Important: convince yourself that this is true__       \n",
      "       \n",
      "The final version of the LR cost function for the whole dataset:      \n",
      "$ J(\\theta) = -\\frac{1}{m}[\\sum\\limits_{i=1}^m~y^{(i)}~log(h_\\theta(x^{(i)})) - (1-y^{(i)})log(1 - h_\\theta(x^{(i)}))] $\n",
      "                  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Training\n",
      "__We want to find:__\n",
      "       \n",
      "$\\displaystyle \\min_{\\theta}J(\\theta) $\n",
      "       \n",
      "given parameters $x$, we predict the $y$ value by:     \n",
      "$ h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^Tx}} $     \n",
      "aka:    \n",
      "$ p(y=1 | x;\\theta) $            \n",
      "       \n",
      "The update template is:      \n",
      "Repeat {       \n",
      "$~~~~\\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta) $            \n",
      "}     \n",
      "$\\alpha$ is the learning rate     \n",
      "We update all $\\theta_j$ __simultaeneously__     \n",
      "       \n",
      "__Note: don't fear the partial derivative, it's really simple in practice:__     \n",
      "      \n",
      "$ \\frac{\\partial}{\\partial\\theta_j}J(\\theta) = \\frac{1}{m}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} $             \n",
      "       \n",
      "__so the update equation becomes: __      \n",
      "\n",
      "Repeat {       \n",
      "$~~~~\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} $            \n",
      "}      \n",
      "__this is identical to the update rule for gradient descent for Linear Regression__      \n",
      "       \n",
      "the vectorized version of the update template (note the missing $j$s):      \n",
      "\n",
      "$~~~~\\theta := \\theta - \\alpha\\frac{1}{m}\\sum\\limits_{i=1}^m[(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}] $      "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Prepare a Dataset\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# some binary classification datasets can be found here: http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html\n",
      "from sklearn.datasets import load_iris\n",
      "import random\n",
      "\n",
      "# Get some data and munge it into the format we want\n",
      "data = load_iris()\n",
      "binary_iris = np.array(data.target) == 0\n",
      "\n",
      "class_map = { True: 1.0, False: 0.0 }\n",
      "binary_y = np.array([ class_map[c] for c in binary_iris ])\n",
      "\n",
      "# the full datasets\n",
      "X = data.data[:data.data.shape[0] - np.int(data.data.shape[0] / 3), :]\n",
      "y = binary_y[:data.data.shape[0] - np.int(data.data.shape[0] / 3)]\n",
      "\n",
      "# split test/train\n",
      "id_list = range(len(data.target))\n",
      "random.shuffle(id_list)\n",
      "train_X = data.data[[id_list[:120]]]\n",
      "test_X = data.data[[id_list[120:]]]\n",
      "train_y = binary_y[[id_list[:120]]]\n",
      "test_y = binary_y[[id_list[120:]]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "# scikit-learn dimension reduction\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "# scikit-learn dataset processing utils\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "\n",
      "df = pd.read_csv('./data/train.csv')\n",
      "df = df.astype('float64')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(42000, 785)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_max_scaler = MinMaxScaler()\n",
      "pca = PCA(n_components=80)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = min_max_scaler.fit_transform(df.ix[:9999,1:])\n",
      "train_X = pca.fit_transform(X)\n",
      "\n",
      "train_y = df.ix[:9999,0]\n",
      "\n",
      "# Xt = min_max_scaler.transform(df.ix[35000:,1:])\n",
      "test_X = min_max_scaler.transform(df.ix[35000:,1:])\n",
      "test_X = pca.transform(test_X)\n",
      "# yt = df.ix[35000:,0]\n",
      "test_y = df.ix[35000:,0] \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class_map = { True: 1.0, False: 0.0 }\n",
      "\n",
      "# binarize train_y and test_y\n",
      "train_y = np.array(train_y) == 1\n",
      "test_y = np.array(test_y) == 1\n",
      "\n",
      "train_y = np.array([ class_map[c] for c in train_y ])\n",
      "test_y = np.array([ class_map[c] for c in test_y ])\n",
      "# test_y[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Implement the update equation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute the hypothesis for the row, subtract y, and put the value in every cell of that row\n",
      "# scale each cell by the x_j of that cell (multiply cellwise with the original array)\n",
      "# average columns, and multiply by alpha\n",
      "# subtract that vector from the previous theta to get the new theta for this iteration\n",
      "\n",
      "# this theta will get updated as the algorithm iterates\n",
      "# theta = np.random.uniform(-1.0,1.0,[1,X.shape[1]])\n",
      "theta = np.zeros((1,train_X.shape[1]))\n",
      "original_theta = np.array(theta)\n",
      "lambd = 1.0\n",
      "\n",
      "# completely vectorized implementation\n",
      "# NOTE: not regularized -- do this as an exercise\n",
      "def iterate(X, y, theta, alpha):\n",
      "    updates = np.average(X * (sigmoid(X, theta).T - y).T, axis=0) * alpha \n",
      "    new_theta = theta - updates\n",
      "    return new_theta\n",
      "\n",
      "# just for demo purposes - a more straightforward version of the function above\n",
      "# regularized iterate\n",
      "def regularized_simple_iterate(X, y, theta, alpha):\n",
      "    hypotheses = sigmoid(X, theta)\n",
      "    minus_y = hypotheses.T - y\n",
      "    scaled_by_x = X * minus_y.T\n",
      "    col_averages = np.average(scaled_by_x, axis=0)\n",
      "    updates = col_averages* alpha\n",
      "    \n",
      "    updates2 = col_averages*alpha -lambd*theta[0]*alpha\n",
      "    updates2[0] = updates2[0]+ (lambd*theta[0][0]*alpha)\n",
      "    new_theta = theta - updates\n",
      "    regularized_theta = theta - updates2\n",
      "   \n",
      "    return regularized_theta\n",
      "\n",
      "def simple_iterate(X, y, theta, alpha):\n",
      "    hypotheses = sigmoid(X, theta)\n",
      "    minus_y = hypotheses.T - y\n",
      "    scaled_by_x = X * minus_y.T\n",
      "    col_averages = np.average(scaled_by_x, axis=0)\n",
      "    updates = col_averages* alpha\n",
      "    new_theta = theta - updates\n",
      "    return new_theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Evaluate performance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's test the accuracy of our classifier\n",
      "def predict(x, theta):\n",
      "    return sigmoid(x, theta)\n",
      "\n",
      "def classes(y):\n",
      "    if y == 1.0:\n",
      "        return True\n",
      "    return False\n",
      "\n",
      "def check_accuracy(predictions, y):\n",
      "    binarized_predictions = predictions >= 0.5\n",
      "    tf = np.array([ classes(c) for c in y ], dtype='bool')\n",
      "    correct = binarized_predictions[:,0] == tf\n",
      "    score = np.sum([ 1 for s in correct if s == True ]) / np.float(len(correct))\n",
      "    return(score)\n",
      "  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To predict, all we need is a theta - let's check performance before training\n",
      "check_accuracy(predict(test_X, original_theta), test_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.11157142857142857"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Regularized Cost Function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# note: this is just for sanity checks\n",
      "def cost_function(X, answers, theta):\n",
      "    total = 0.0\n",
      "    for x,y in zip(X,answers):\n",
      "        hyp = sigmoid(x, theta)\n",
      "        total += ( (-y * np.log(hyp)) - ((1-y) * np.log(1-hyp)) ) \n",
      "    cost = (total / len(answers))\n",
      "    return cost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# note: this is just for sanity checks\n",
      "def regularized_cost_function(X, answers, theta):\n",
      "    total = 0.0\n",
      "    for x,y in zip(X,answers):\n",
      "        hyp = sigmoid(x, theta)\n",
      "        total += ( (-y * np.log(hyp)) - ((1-y) * np.log(1-hyp)) ) \n",
      "    cost = (total / len(answers)) + ((lambd/len(answers))*sum(theta[1:]*theta[1:]))\n",
      "    return cost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print the original theta, and the output of the cost function\n",
      "print(theta)\n",
      "print(cost_function(train_X, train_y, theta))\n",
      "test =  []\n",
      "\n",
      "def gradient_descent(X, y, theta, alpha, num_iterations=100):\n",
      "    working_theta = np.array(theta)\n",
      "    all_cost =[]\n",
      "    for i in range(num_iterations):\n",
      "        working_theta = regularized_simple_iterate(X, y, working_theta, alpha)\n",
      "#         working_theta = simple_iterate(X, y, working_theta, alpha)\n",
      "        all_cost.append(regularized_cost_function(train_X, train_y, working_theta))\n",
      "#         all_cost.append(cost_function(train_X, train_y, working_theta))\n",
      "        #j = j+1\n",
      "    test.append(all_cost)    \n",
      "    return np.array(working_theta)\n",
      "        \n",
      "num_iterations = 30\n",
      "j = 0   \n",
      "\n",
      "alpha = 0.005\n",
      "\n",
      "best_theta = gradient_descent(train_X, train_y, theta, alpha, num_iterations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
        "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
        "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
        "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
        "   0.  0.  0.  0.  0.  0.  0.  0.]]\n",
        "[ 0.69314718]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = predict(test_X, best_theta)    \n",
      "check_accuracy(predictions, test_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "0.67000000000000004"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test with some different learning rates\n",
      "alpha = [0.005,0.01,0.03,0.06,0.1]\n",
      "for i in alpha:\n",
      "    best_theta = gradient_descent(train_X, train_y, theta, i, num_iterations)\n",
      "\n",
      "    j=j+1\n",
      "    print i;\n",
      "all_cost\n",
      "\n",
      "plt.clf()\n",
      "plt.plot(test[0],color='yellow',lw=2)\n",
      "plt.plot(test[1],color='blue', lw=2)\n",
      "plt.plot(test[2],color='green', lw=2)\n",
      "plt.plot(test[3],color='red', lw=2)\n",
      "plt.plot(test[4],color='grey', lw=2)\n",
      "plt.xlabel('hypothesis')\n",
      "plt.ylabel('cost')\n",
      "plt.ylim([0,0.2])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the following graph shows what the cost function looks like for y = 1 and y = 0\n",
      "plt.clf()\n",
      "\n",
      "def positive_cost(hyp_value):\n",
      "    return -(np.log(hyp_value))\n",
      "\n",
      "def negative_cost(hyp_value):\n",
      "    return -(np.log(1 - hyp_value))\n",
      "\n",
      "# map cost function over some numbers\n",
      "pos1_x = np.arange(0.01, 1, .01)\n",
      "pos1_y = [ positive_cost(n) for n in pos1_x ]\n",
      "\n",
      "\n",
      "neg1_x = np.arange(0.01, 1, .01)\n",
      "neg1_y = [ negative_cost(n) for n in neg1_x ]\n",
      "\n",
      "# add a horizontal line at 0\n",
      "#plt.axvline(x=0, ymin=0, ymax=1, ls='--')\n",
      "\n",
      "plt.plot(pos1_x, pos1_y, color='blue', lw=2)\n",
      "plt.plot(neg1_x, neg1_y, color='red', lw=2)\n",
      "\n",
      "plt.xlabel('hypothesis')\n",
      "plt.ylabel('cost')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Question: Explain why this is a good cost function for learning the parameters of a binary classifier__"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercises:      \n",
      "(1) Plot the regularized cost function with several different values      \n",
      "(2) Increase the number of features (increase the number of principle components in PCA), and plot how the performance changes     \n",
      "(3) Refactor the vectorized 'iterate' function to use regularization\n",
      "(4) Extend our LR implementation to a multi-class implementation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}